{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike sort\n",
    "\n",
    "This notebook is a modified version of the *3-sort_spikes* in the chronic ephys processing pipeline\n",
    "\n",
    "This notebook allows you to concatenate multiple recordings to be spike sorted together. *Be careful, this is only recommended for consecutive recordings on the same date.*\n",
    "\n",
    "Use the environment **spikeproc** to run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"NPY_MATLAB_PATH\"] = '/mnt/cube/chronic_ephys/code/npy-matlab'\n",
    "os.environ[\"KILOSORT2_PATH\"] = '/mnt/cube/chronic_ephys/code/Kilosort2'\n",
    "os.environ[\"KILOSORT3_PATH\"] = '/mnt/cube/chronic_ephys/code/Kilosort'\n",
    "import spikeinterface.full as si\n",
    "import sys\n",
    "import traceback\n",
    "sys.path.append('/mnt/cube/lo/envs/ceciestunepipe/')\n",
    "from ceciestunepipe.file import bcistructure as et\n",
    "from ceciestunepipe.mods import probe_maps as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non default spike sorting parameters\n",
    "sort_params_dict = {'minFR':0.001, 'minfr_goodchannels':0.001}\n",
    "\n",
    "# waveform extraction parameters\n",
    "wave_params_dict = {'ms_before':1, 'ms_after':2, 'max_spikes_per_unit':500,\n",
    "                    'sparse':True, 'num_spikes_for_sparsity':100, 'method':'radius',\n",
    "                    'radius_um':40, 'n_components':5, 'mode':'by_channel_local'}\n",
    "\n",
    "# print stuff\n",
    "verbose = True\n",
    "\n",
    "# errors break sorting\n",
    "raise_error = False\n",
    "\n",
    "# restrict sorting to a specific GPU\n",
    "restrict_to_gpu = 1 # 0 1 None\n",
    "\n",
    "# use specific GPU if specified\n",
    "if restrict_to_gpu is not None:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(restrict_to_gpu)\n",
    "\n",
    "# parallel processing params\n",
    "job_kwargs = dict(n_jobs=28,chunk_duration=\"1s\",progress_bar=False)\n",
    "si.set_global_job_kwargs(**job_kwargs)\n",
    "\n",
    "# force processing of previous failed sorts\n",
    "skip_failed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_par = {\n",
    "    'bird':'z_y19o20_21', # bird ID\n",
    "    'sess':'2021-10-27', # session (will process all epochs within this date)\n",
    "    'probes':{}, # probes of interest (needed for oe, not needed for sglx)\n",
    "    'sort':'sort_0', # label for this sort instance\n",
    "    'sorter':'kilosort3', # sort method\n",
    "    'sort_params':sort_params_dict, # non-default sort params\n",
    "    'wave_params':wave_params_dict, # waveform extraction params\n",
    "    'ephys_software':'sglx' # sglx or oe\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort..\n",
      "RUNNING SHELL SCRIPT: /mnt/cube/chronic_ephys/der/z_y19o20_21/2021-10-27/sglx/1033_undirected_g0-1142_directed_g0/kilosort3/sort_0/sorter_output/run_kilosort3.sh\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2023 The MathWorks, Inc.\n",
      "\n",
      "                  R2023a (9.14.0.2206163) 64-bit (glnxa64)\n",
      "\n",
      "                             February 22, 2023\n",
      "\n",
      "\n",
      "\n",
      "Warning: X does not support locale en_US.UTF-8\n",
      "\n",
      " \n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      " \n",
      "\n",
      "Time   0s. Computing whitening matrix.. \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Time  84s. Loading raw data and applying filters... \n",
      "\n",
      "Time 1855s. Finished preprocessing 3051 batches. \n",
      "\n",
      "Drift correction ENABLED\n",
      "\n",
      "vertical pitch size is 20 \n",
      "\n",
      "horizontal pitch size is 32 \n",
      "\n",
      "     0    16    32    48\n",
      "\n",
      "\n",
      "\n",
      "   766\n",
      "\n",
      "\n",
      "\n",
      "0.35 sec, 1 batches, 4812 spikes \n",
      "\n",
      "42.25 sec, 101 batches, 487940 spikes \n",
      "\n",
      "87.85 sec, 201 batches, 948560 spikes \n",
      "\n",
      "134.16 sec, 301 batches, 1297559 spikes \n",
      "\n",
      "175.41 sec, 401 batches, 1688206 spikes \n",
      "\n",
      "218.56 sec, 501 batches, 2100184 spikes \n",
      "\n",
      "263.32 sec, 601 batches, 2545356 spikes \n",
      "\n",
      "306.20 sec, 701 batches, 2942784 spikes \n",
      "\n",
      "354.31 sec, 801 batches, 3388741 spikes \n",
      "\n",
      "399.88 sec, 901 batches, 3852700 spikes \n",
      "\n",
      "447.70 sec, 1001 batches, 4322840 spikes \n",
      "\n",
      "491.92 sec, 1101 batches, 4795105 spikes \n",
      "\n",
      "537.49 sec, 1201 batches, 5261862 spikes \n",
      "\n",
      "577.12 sec, 1301 batches, 5737970 spikes \n",
      "\n",
      "620.53 sec, 1401 batches, 6220982 spikes \n",
      "\n",
      "664.97 sec, 1501 batches, 6726176 spikes \n",
      "\n",
      "706.73 sec, 1601 batches, 7188134 spikes \n",
      "\n",
      "747.77 sec, 1701 batches, 7640171 spikes \n",
      "\n",
      "790.28 sec, 1801 batches, 8047025 spikes \n",
      "\n",
      "830.55 sec, 1901 batches, 8480077 spikes \n",
      "\n",
      "868.45 sec, 2001 batches, 8913801 spikes \n",
      "\n",
      "907.50 sec, 2101 batches, 9355598 spikes \n",
      "\n",
      "947.95 sec, 2201 batches, 9823722 spikes \n",
      "\n",
      "986.13 sec, 2301 batches, 10282320 spikes \n",
      "\n",
      "1023.93 sec, 2401 batches, 10739722 spikes \n",
      "\n",
      "1060.07 sec, 2501 batches, 11211133 spikes \n",
      "\n",
      "1095.46 sec, 2601 batches, 11658551 spikes \n",
      "\n",
      "1132.89 sec, 2701 batches, 12131186 spikes \n",
      "\n",
      "1168.87 sec, 2801 batches, 12598685 spikes \n",
      "\n",
      "1206.37 sec, 2901 batches, 13062979 spikes \n",
      "\n",
      "1242.33 sec, 3001 batches, 13543532 spikes \n",
      "\n",
      "1260.63 sec, 3051 batches, 13786656 spikes \n",
      "\n",
      "time 2612.80, Shifted up/down 3051 batches. \n",
      "\n",
      "0.28 sec, 1 batches, 4894 spikes \n",
      "\n",
      "32.57 sec, 101 batches, 507510 spikes \n",
      "\n",
      "67.23 sec, 201 batches, 997029 spikes \n",
      "\n",
      "104.73 sec, 301 batches, 1376474 spikes \n",
      "\n",
      "142.14 sec, 401 batches, 1806462 spikes \n",
      "\n",
      "179.57 sec, 501 batches, 2262876 spikes \n",
      "\n",
      "215.73 sec, 601 batches, 2759438 spikes \n",
      "\n",
      "249.69 sec, 701 batches, 3199595 spikes \n",
      "\n",
      "284.71 sec, 801 batches, 3696099 spikes \n",
      "\n",
      "319.83 sec, 901 batches, 4216738 spikes \n",
      "\n",
      "359.28 sec, 1001 batches, 4752635 spikes \n",
      "\n",
      "395.81 sec, 1101 batches, 5294205 spikes \n",
      "\n",
      "433.56 sec, 1201 batches, 5773926 spikes \n",
      "\n",
      "470.74 sec, 1301 batches, 6222771 spikes \n",
      "\n",
      "504.12 sec, 1401 batches, 6674730 spikes \n",
      "\n",
      "537.87 sec, 1501 batches, 7150745 spikes \n",
      "\n",
      "572.07 sec, 1601 batches, 7583088 spikes \n",
      "\n",
      "608.72 sec, 1701 batches, 8008446 spikes \n",
      "\n",
      "643.17 sec, 1801 batches, 8395738 spikes \n",
      "\n",
      "679.40 sec, 1901 batches, 8805397 spikes \n",
      "\n",
      "725.45 sec, 2001 batches, 9220751 spikes \n",
      "\n",
      "769.39 sec, 2101 batches, 9646444 spikes \n",
      "\n",
      "806.21 sec, 2201 batches, 10097166 spikes \n",
      "\n",
      "842.87 sec, 2301 batches, 10541847 spikes \n",
      "\n",
      "877.66 sec, 2401 batches, 10989075 spikes \n",
      "\n",
      "918.11 sec, 2501 batches, 11449980 spikes \n",
      "\n",
      "958.24 sec, 2601 batches, 11890969 spikes \n",
      "\n",
      "996.71 sec, 2701 batches, 12354851 spikes \n",
      "\n",
      "1034.47 sec, 2801 batches, 12818731 spikes \n",
      "\n",
      "1075.73 sec, 2901 batches, 13286705 spikes \n",
      "\n",
      "1115.63 sec, 3001 batches, 13772198 spikes \n",
      "\n",
      "1135.55 sec, 3051 batches, 14018902 spikes \n",
      "\n",
      "time 0.00, GROUP 1/96, units 0 \n",
      "\n",
      "time 11.41, GROUP 6/96, units 9 \n",
      "\n",
      "time 30.78, GROUP 11/96, units 27 \n",
      "\n",
      "time 182.48, GROUP 16/96, units 132 \n",
      "\n",
      "time 263.90, GROUP 21/96, units 188 \n",
      "\n",
      "time 351.19, GROUP 26/96, units 250 \n",
      "\n",
      "time 358.31, GROUP 31/96, units 258 \n",
      "\n",
      "time 361.58, GROUP 36/96, units 264 \n",
      "\n",
      "time 364.70, GROUP 41/96, units 272 \n",
      "\n",
      "time 387.60, GROUP 46/96, units 308 \n",
      "\n",
      "time 408.92, GROUP 51/96, units 337 \n",
      "\n",
      "time 420.44, GROUP 56/96, units 352 \n",
      "\n",
      "time 443.09, GROUP 61/96, units 378 \n",
      "\n",
      "time 451.28, GROUP 66/96, units 389 \n",
      "\n",
      "time 458.69, GROUP 71/96, units 400 \n",
      "\n",
      "time 462.06, GROUP 76/96, units 408 \n",
      "\n",
      "time 474.25, GROUP 81/96, units 426 \n",
      "\n",
      "time 482.33, GROUP 86/96, units 440 \n",
      "\n",
      "time 488.69, GROUP 91/96, units 458 \n",
      "\n",
      "time 492.64, GROUP 96/96, units 466 \n",
      "\n",
      "Elapsed time is 493.519968 seconds.\n",
      "\n",
      "Time 496s. Final spike extraction ...\n",
      "\n",
      "496.35 sec, 1 / 3051 batches, 467 units, nspks: 5750, mu: 14.8693, nst0: 5750 \n",
      "\n",
      "538.89 sec, 101 / 3051 batches, 467 units, nspks: 597764, mu: 14.8693, nst0: 5281 \n",
      "\n",
      "578.47 sec, 201 / 3051 batches, 467 units, nspks: 1176684, mu: 14.8693, nst0: 5684 \n",
      "\n",
      "614.62 sec, 301 / 3051 batches, 467 units, nspks: 1622713, mu: 14.8693, nst0: 4092 \n",
      "\n",
      "653.39 sec, 401 / 3051 batches, 467 units, nspks: 2127233, mu: 14.8693, nst0: 6509 \n",
      "\n",
      "691.69 sec, 501 / 3051 batches, 467 units, nspks: 2657144, mu: 14.8693, nst0: 5915 \n",
      "\n",
      "728.08 sec, 601 / 3051 batches, 467 units, nspks: 3229518, mu: 14.8693, nst0: 6459 \n",
      "\n",
      "763.24 sec, 701 / 3051 batches, 467 units, nspks: 3742703, mu: 14.8693, nst0: 6491 \n",
      "\n",
      "798.00 sec, 801 / 3051 batches, 467 units, nspks: 4294106, mu: 14.8693, nst0: 5876 \n",
      "\n",
      "834.33 sec, 901 / 3051 batches, 467 units, nspks: 4889600, mu: 14.8693, nst0: 6187 \n",
      "\n",
      "872.20 sec, 1001 / 3051 batches, 467 units, nspks: 5499026, mu: 14.8693, nst0: 5946 \n",
      "\n",
      "909.43 sec, 1101 / 3051 batches, 467 units, nspks: 6117484, mu: 14.8693, nst0: 6426 \n",
      "\n",
      "945.71 sec, 1201 / 3051 batches, 467 units, nspks: 6676675, mu: 14.8693, nst0: 5078 \n",
      "\n",
      "980.16 sec, 1301 / 3051 batches, 467 units, nspks: 7217044, mu: 14.8693, nst0: 5042 \n",
      "\n",
      "1016.72 sec, 1401 / 3051 batches, 467 units, nspks: 7758046, mu: 14.8693, nst0: 5590 \n",
      "\n",
      "1052.53 sec, 1501 / 3051 batches, 467 units, nspks: 8315853, mu: 14.8693, nst0: 5381 \n",
      "\n",
      "1088.15 sec, 1601 / 3051 batches, 467 units, nspks: 8822773, mu: 14.8693, nst0: 4938 \n",
      "\n",
      "1132.17 sec, 1701 / 3051 batches, 467 units, nspks: 9320992, mu: 14.8693, nst0: 4929 \n",
      "\n",
      "1167.36 sec, 1801 / 3051 batches, 467 units, nspks: 9768334, mu: 14.8693, nst0: 5541 \n",
      "\n",
      "1208.56 sec, 1901 / 3051 batches, 467 units, nspks: 10236501, mu: 14.8693, nst0: 5682 \n",
      "\n",
      "1244.22 sec, 2001 / 3051 batches, 467 units, nspks: 10721028, mu: 14.8693, nst0: 5928 \n",
      "\n",
      "1278.84 sec, 2101 / 3051 batches, 467 units, nspks: 11221546, mu: 14.8693, nst0: 5815 \n",
      "\n",
      "1315.05 sec, 2201 / 3051 batches, 467 units, nspks: 11757525, mu: 14.8693, nst0: 5959 \n",
      "\n",
      "1350.47 sec, 2301 / 3051 batches, 467 units, nspks: 12280932, mu: 14.8693, nst0: 5288 \n",
      "\n",
      "1388.25 sec, 2401 / 3051 batches, 467 units, nspks: 12810074, mu: 14.8693, nst0: 5193 \n",
      "\n",
      "1426.28 sec, 2501 / 3051 batches, 467 units, nspks: 13365410, mu: 14.8693, nst0: 5586 \n",
      "\n",
      "1463.48 sec, 2601 / 3051 batches, 467 units, nspks: 13891333, mu: 14.8693, nst0: 5350 \n",
      "\n",
      "1500.60 sec, 2701 / 3051 batches, 467 units, nspks: 14444495, mu: 14.8693, nst0: 6034 \n",
      "\n",
      "1537.11 sec, 2801 / 3051 batches, 467 units, nspks: 15009688, mu: 14.8693, nst0: 5206 \n",
      "\n",
      "1573.42 sec, 2901 / 3051 batches, 467 units, nspks: 15574957, mu: 14.8693, nst0: 5783 \n",
      "\n",
      "1612.69 sec, 3001 / 3051 batches, 467 units, nspks: 16159596, mu: 14.8693, nst0: 5633 \n",
      "\n",
      "Elapsed time is 1631.126160 seconds.\n",
      "\n",
      "time 0.00, GROUP 1/96, units 0 \n",
      "\n",
      "time 10.35, GROUP 6/96, units 15 \n",
      "\n",
      "time 45.06, GROUP 11/96, units 34 \n",
      "\n",
      "time 213.75, GROUP 16/96, units 81 \n",
      "\n",
      "time 325.97, GROUP 21/96, units 127 \n",
      "\n",
      "time 384.01, GROUP 26/96, units 162 \n",
      "\n",
      "time 398.94, GROUP 31/96, units 180 \n",
      "\n",
      "time 405.30, GROUP 36/96, units 195 \n",
      "\n",
      "time 411.70, GROUP 41/96, units 212 \n",
      "\n",
      "time 437.26, GROUP 46/96, units 258 \n",
      "\n",
      "time 470.58, GROUP 51/96, units 300 \n",
      "\n",
      "time 485.81, GROUP 56/96, units 319 \n",
      "\n",
      "time 508.83, GROUP 61/96, units 343 \n",
      "\n",
      "time 520.57, GROUP 66/96, units 356 \n",
      "\n",
      "time 536.94, GROUP 71/96, units 386 \n",
      "\n",
      "time 546.84, GROUP 76/96, units 409 \n",
      "\n",
      "time 560.99, GROUP 81/96, units 427 \n",
      "\n",
      "time 571.80, GROUP 86/96, units 442 \n",
      "\n",
      "time 584.91, GROUP 91/96, units 474 \n",
      "\n",
      "time 592.13, GROUP 96/96, units 488 \n",
      "\n",
      "Elapsed time is 593.008000 seconds.\n",
      "\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "\n",
      "\n",
      "   121\n",
      "\n",
      "\n",
      "\n",
      "initialized spike counts\n",
      "\n",
      "merged 155 into 143 \n",
      "\n",
      "merged 140 into 134 \n",
      "\n",
      "merged 50 into 62 \n",
      "\n",
      "merged 93 into 70 \n",
      "\n",
      "merged 101 into 83 \n",
      "\n",
      "merged 131 into 125 \n",
      "\n",
      "merged 108 into 110 \n",
      "\n",
      "merged 89 into 99 \n",
      "\n",
      "merged 139 into 134 \n",
      "\n",
      "merged 92 into 70 \n",
      "\n",
      "merged 317 into 322 \n",
      "\n",
      "merged 49 into 60 \n",
      "\n",
      "merged 82 into 99 \n",
      "\n",
      "merged 72 into 64 \n",
      "\n",
      "merged 287 into 269 \n",
      "\n",
      "merged 59 into 63 \n",
      "\n",
      "merged 157 into 143 \n",
      "\n",
      "merged 76 into 64 \n",
      "\n",
      "merged 162 into 151 \n",
      "\n",
      "merged 150 into 153 \n",
      "\n",
      "merged 312 into 323 \n",
      "\n",
      "merged 350 into 354 \n",
      "\n",
      "merged 257 into 251 \n",
      "\n",
      "merged 146 into 159 \n",
      "\n",
      "merged 65 into 48 \n",
      "\n",
      "merged 320 into 331 \n",
      "\n",
      "merged 429 into 426 \n",
      "\n",
      "merged 286 into 295 \n",
      "\n",
      "merged 145 into 137 \n",
      "\n",
      "merged 79 into 91 \n",
      "\n",
      "merged 87 into 99 \n",
      "\n",
      "merged 56 into 43 \n",
      "\n",
      "merged 66 into 57 \n",
      "\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "\n",
      "\n",
      "   104\n",
      "\n",
      "\n",
      "\n",
      "Saving results to Phy\n",
      "\n",
      "kilosort3 run time 8090.67s\n",
      "bandpass..\n",
      "waveform..\n",
      "metrics..\n",
      "Computing num_spikes\n",
      "Computing firing_rate\n",
      "Computing presence_ratio\n",
      "Computing snr\n",
      "Computing isi_violation\n",
      "Computing rp_violation\n",
      "Computing sliding_rp_violation\n",
      "Computing amplitude_cutoff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cube/lo/envs/spikeproc/lib/python3.8/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:590: UserWarning: Units [2, 3, 9, 11, 12, 13, 16, 24, 26, 28, 31, 32, 39, 51, 52, 53, 72, 73, 83, 84, 87, 93, 94, 95, 104, 108, 110, 111, 112, 114, 115, 116, 118, 131, 146, 157, 164, 165, 166, 170, 176, 178, 180, 181, 184, 186, 187, 189, 190, 191, 193, 195, 197, 198, 201, 202, 204, 207, 208, 209, 212, 214, 216, 221, 222, 223, 225, 228, 230, 231, 232, 234, 235, 238, 240, 242, 243, 247, 253, 255, 259, 261, 269, 276, 277, 280, 283, 284, 287, 289, 290, 297, 298, 304, 323, 326, 328, 336, 337, 339, 341, 348, 350, 357, 358, 360, 361, 362, 363, 364, 366, 367, 368, 369, 371, 372, 373, 376, 377, 378, 379, 380, 381, 383, 384, 386, 387, 389, 390, 391, 393, 394, 395, 396, 397, 398, 399, 402, 403, 404, 405, 406, 410, 413, 415, 416, 418, 419, 420, 421, 422, 423, 424, 427, 429, 430, 431, 436, 438, 439, 440, 442, 443, 444, 445, 446, 447, 448, 450, 451, 452, 453, 454, 455, 457, 458, 459, 461, 462, 463, 464, 466, 468, 469, 470, 471, 472, 474, 475, 476, 478, 479, 480, 481, 484, 485] have too few spikes and amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Units {nan_units} have too few spikes and \" \"amplitude_cutoff is set to NaN\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing amplitude_median\n",
      "COMPLETE!!\n",
      "['z_y19o20_21', '2021-10-27', 'sglx', '1033_undirected_g0-1142_directed_g0', 'COMPLETE']\n",
      "CPU times: user 1h 22min 31s, sys: 37.3 s, total: 1h 23min 8s\n",
      "Wall time: 4h 39min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# get epochs\n",
    "sess_epochs = et.list_ephys_epochs(sess_par)\n",
    "concat_epochs = '-'.join(sess_epochs)\n",
    "\n",
    "# set output directory\n",
    "epoch_struct = et.sgl_struct(sess_par,concat_epochs,ephys_software=sess_par['ephys_software'])\n",
    "sort_folder = epoch_struct['folders']['derived'] + '/{}/{}/'.format(sess_par['sorter'],sess_par['sort'])\n",
    "\n",
    "# get spike sort log\n",
    "log_dir = os.path.join('/mnt/cube/chronic_ephys/log', sess_par['bird'], sess_par['sess'])\n",
    "try:\n",
    "    with open(os.path.join(log_dir, concat_epochs+'_spikesort.log'), 'r') as f:\n",
    "        log_message=f.readline() # read the first line of the log file\n",
    "    if log_message[:-1] == sess_par['bird']+' '+sess_par['sess']+' sort complete without error':\n",
    "        print(sess_par['bird'],sess_par['sess'],'already exists -- skipping sort')\n",
    "        run_proc = False\n",
    "    elif log_message[:-1] == sess_par['bird']+' '+sess_par['sess']+' sort failed':\n",
    "        if skip_failed:\n",
    "            print(sess_par['bird'],sess_par['sess'],'previously failed -- skipping sort')\n",
    "            run_proc = False\n",
    "        else:\n",
    "            run_proc = True\n",
    "    else: # uninterpretable log file\n",
    "        run_proc = True\n",
    "except: # no existing log file\n",
    "    run_proc = True\n",
    "\n",
    "# run sort\n",
    "if run_proc:\n",
    "    try: \n",
    "        # load recordings\n",
    "        rec_path = '/'.join(epoch_struct['folders']['sglx'].split('/')[:-1])\n",
    "        epoch_list = [e for e in os.listdir(rec_path) if os.path.isdir(os.path.join(rec_path,e))]\n",
    "        recording_list = []\n",
    "        for this_epoch in epoch_list:\n",
    "            this_rec = si.read_spikeglx(folder_path=os.path.join(rec_path,this_epoch), stream_name='imec0.ap')\n",
    "            \n",
    "            # ibl destriping\n",
    "            this_rec = si.highpass_filter(recording=this_rec)\n",
    "            this_rec = si.phase_shift(recording=this_rec)\n",
    "            bad_good_channel_ids = si.detect_bad_channels(recording=this_rec)\n",
    "            if len(bad_good_channel_ids[0]) > 0:\n",
    "                this_rec = si.interpolate_bad_channels(recording=this_rec,bad_channel_ids=bad_good_channel_ids[0])\n",
    "            this_rec = si.highpass_spatial_filter(recording=this_rec)\n",
    "            \n",
    "            recording_list.append(this_rec)\n",
    "        \n",
    "        # concatenate recordings\n",
    "        this_rec_p = si.concatenate_recordings(recording_list)\n",
    "        \n",
    "        # set sort params\n",
    "        sort_params = si.get_default_sorter_params(sess_par['sorter'])\n",
    "        for this_param in sess_par['sort_params'].keys():\n",
    "            sort_params[this_param] = sess_par['sort_params'][this_param]\n",
    "        # run sort\n",
    "        print('sort..')\n",
    "        this_sort = si.run_sorter(sorter_name=sess_par['sorter'],recording=this_rec_p,output_folder=sort_folder,\n",
    "                             remove_existing_folder=True,delete_output_folder=False,delete_container_files=False,\n",
    "                             verbose=verbose,raise_error=raise_error,**sort_params)\n",
    "        # bandpass recording before waveform extraction\n",
    "        print('bandpass..')\n",
    "        this_rec_pf = si.bandpass_filter(recording=this_rec_p)\n",
    "        # extract waveforms\n",
    "        print('waveform..')\n",
    "        wave_params = sess_par['wave_params']\n",
    "        wave = si.extract_waveforms(this_rec_pf,this_sort,folder=os.path.join(sort_folder,'waveforms'),\n",
    "                                    ms_before=wave_params['ms_before'],ms_after=wave_params['ms_after'],\n",
    "                                    max_spikes_per_unit=wave_params['max_spikes_per_unit'],\n",
    "                                    sparse=wave_params['sparse'],num_spikes_for_sparsity=wave_params['num_spikes_for_sparsity'],\n",
    "                                    method=wave_params['method'],radius_um=wave_params['radius_um'],overwrite=True,**job_kwargs)\n",
    "        # compute metrics\n",
    "        print('metrics..')\n",
    "        loc = si.compute_unit_locations(waveform_extractor=wave)\n",
    "        cor = si.compute_correlograms(waveform_or_sorting_extractor=wave)\n",
    "        sim = si.compute_template_similarity(waveform_extractor=wave)\n",
    "        amp = si.compute_spike_amplitudes(waveform_extractor=wave,**job_kwargs)\n",
    "        pca = si.compute_principal_components(waveform_extractor=wave,n_components=wave_params['n_components'],\n",
    "                                              mode=wave_params['mode'],**job_kwargs)\n",
    "        met = si.compute_quality_metrics(waveform_extractor=wave,verbose=verbose,**job_kwargs)\n",
    "\n",
    "        # mark complete\n",
    "        print('COMPLETE!!')\n",
    "\n",
    "        # log complete sort\n",
    "        if not os.path.exists(log_dir): os.makedirs(log_dir)\n",
    "        with open(os.path.join(log_dir, concat_epochs+'_spikesort.log'), 'w') as f:\n",
    "            f.write(sess_par['bird']+' '+sess_par['sess']+' sort complete without error\\n')\n",
    "        sort_summary = [sess_par['bird'],sess_par['sess'],sess_par['ephys_software'],concat_epochs,'COMPLETE']\n",
    "                    \n",
    "    except Exception as e:\n",
    "        # mark exception\n",
    "        print(\"An exception occurred:\", e)\n",
    "\n",
    "        # log failed sort[os.path.join(d, o) for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]\n",
    "        if not os.path.exists(log_dir): os.makedirs(log_dir)\n",
    "        with open(os.path.join(log_dir, concat_epochs+'_spikesort.log'), 'w') as f:\n",
    "            f.write(sess_par['bird']+' '+sess_par['sess']+' sort failed\\n')\n",
    "            f.write(traceback.format_exc())\n",
    "        sort_summary = [sess_par['bird'],sess_par['sess'],sess_par['ephys_software'],concat_epochs,'FAIL']\n",
    "else:\n",
    "    sort_summary = [sess_par['bird'],sess_par['sess'],sess_par['ephys_software'],concat_epochs,'EXISTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sort_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikeproc",
   "language": "python",
   "name": "spikeproc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
